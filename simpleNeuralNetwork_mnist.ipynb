{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = input_data.read_data_sets('data/', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NETWORK READY\n"
     ]
    }
   ],
   "source": [
    "# NETWORK TOPOLOGIES\n",
    "n_hidden_1 = 256 \n",
    "n_hidden_2 = 128 \n",
    "n_input    = 784 \n",
    "n_classes  = 10  \n",
    "\n",
    "# INPUTS AND OUTPUTS\n",
    "x = tf.placeholder(\"float\", [None, n_input])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])\n",
    "    \n",
    "# NETWORK PARAMETERS\n",
    "stddev = 0.1\n",
    "weights = {\n",
    "    'w1': tf.Variable(tf.random_normal([n_input, n_hidden_1], stddev=stddev)),\n",
    "    'w2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2], stddev=stddev)),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_2, n_classes], stddev=stddev))\n",
    "}\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}\n",
    "print (\"NETWORK READY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multilayer_perceptron(_X, _weights, _biases):\n",
    "    layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(_X, _weights['w1']), _biases['b1'])) \n",
    "    layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, _weights['w2']), _biases['b2']))\n",
    "    return (tf.matmul(layer_2, _weights['out']) + _biases['out'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-7-a0ef0367857e>:7: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "FUNCTIONS READY\n"
     ]
    }
   ],
   "source": [
    "# PREDICTION\n",
    "pred = multilayer_perceptron(x, weights, biases)\n",
    "\n",
    "# LOSS AND OPTIMIZER\n",
    "#cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred, y)) \n",
    "#使用交叉熵损失函数\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "\n",
    "optm = tf.train.GradientDescentOptimizer(learning_rate=0.001).minimize(cost) \n",
    "corr = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))    \n",
    "accr = tf.reduce_mean(tf.cast(corr, \"float\"))\n",
    "\n",
    "# INITIALIZER\n",
    "init = tf.global_variables_initializer()\n",
    "print (\"FUNCTIONS READY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 003/200 cost: 2.261031714\n",
      "TRAIN ACCURACY: 0.260\n",
      "TEST ACCURACY: 0.274\n",
      "Epoch: 007/200 cost: 2.222461201\n",
      "TRAIN ACCURACY: 0.370\n",
      "TEST ACCURACY: 0.383\n",
      "Epoch: 011/200 cost: 2.179163245\n",
      "TRAIN ACCURACY: 0.390\n",
      "TEST ACCURACY: 0.445\n",
      "Epoch: 015/200 cost: 2.128761653\n",
      "TRAIN ACCURACY: 0.360\n",
      "TEST ACCURACY: 0.486\n",
      "Epoch: 019/200 cost: 2.069107491\n",
      "TRAIN ACCURACY: 0.510\n",
      "TEST ACCURACY: 0.518\n",
      "Epoch: 023/200 cost: 1.998663956\n",
      "TRAIN ACCURACY: 0.480\n",
      "TEST ACCURACY: 0.553\n",
      "Epoch: 027/200 cost: 1.916838992\n",
      "TRAIN ACCURACY: 0.640\n",
      "TEST ACCURACY: 0.577\n",
      "Epoch: 031/200 cost: 1.824643999\n",
      "TRAIN ACCURACY: 0.600\n",
      "TEST ACCURACY: 0.606\n",
      "Epoch: 035/200 cost: 1.724722378\n",
      "TRAIN ACCURACY: 0.560\n",
      "TEST ACCURACY: 0.638\n",
      "Epoch: 039/200 cost: 1.621072648\n",
      "TRAIN ACCURACY: 0.640\n",
      "TEST ACCURACY: 0.661\n",
      "Epoch: 043/200 cost: 1.517844524\n",
      "TRAIN ACCURACY: 0.740\n",
      "TEST ACCURACY: 0.683\n",
      "Epoch: 047/200 cost: 1.418573518\n",
      "TRAIN ACCURACY: 0.660\n",
      "TEST ACCURACY: 0.704\n",
      "Epoch: 051/200 cost: 1.325776476\n",
      "TRAIN ACCURACY: 0.690\n",
      "TEST ACCURACY: 0.722\n",
      "Epoch: 055/200 cost: 1.240805270\n",
      "TRAIN ACCURACY: 0.700\n",
      "TEST ACCURACY: 0.739\n",
      "Epoch: 059/200 cost: 1.164067064\n",
      "TRAIN ACCURACY: 0.760\n",
      "TEST ACCURACY: 0.753\n",
      "Epoch: 063/200 cost: 1.095332300\n",
      "TRAIN ACCURACY: 0.670\n",
      "TEST ACCURACY: 0.762\n",
      "Epoch: 067/200 cost: 1.034015818\n",
      "TRAIN ACCURACY: 0.760\n",
      "TEST ACCURACY: 0.774\n",
      "Epoch: 071/200 cost: 0.979352564\n",
      "TRAIN ACCURACY: 0.720\n",
      "TEST ACCURACY: 0.785\n",
      "Epoch: 075/200 cost: 0.930568824\n",
      "TRAIN ACCURACY: 0.800\n",
      "TEST ACCURACY: 0.793\n",
      "Epoch: 079/200 cost: 0.886956343\n",
      "TRAIN ACCURACY: 0.710\n",
      "TEST ACCURACY: 0.801\n",
      "Epoch: 083/200 cost: 0.847864635\n",
      "TRAIN ACCURACY: 0.760\n",
      "TEST ACCURACY: 0.809\n",
      "Epoch: 087/200 cost: 0.812719546\n",
      "TRAIN ACCURACY: 0.820\n",
      "TEST ACCURACY: 0.814\n",
      "Epoch: 091/200 cost: 0.781042270\n",
      "TRAIN ACCURACY: 0.810\n",
      "TEST ACCURACY: 0.821\n",
      "Epoch: 095/200 cost: 0.752382289\n",
      "TRAIN ACCURACY: 0.820\n",
      "TEST ACCURACY: 0.825\n",
      "Epoch: 099/200 cost: 0.726397662\n",
      "TRAIN ACCURACY: 0.780\n",
      "TEST ACCURACY: 0.830\n",
      "Epoch: 103/200 cost: 0.702761888\n",
      "TRAIN ACCURACY: 0.820\n",
      "TEST ACCURACY: 0.836\n",
      "Epoch: 107/200 cost: 0.681187652\n",
      "TRAIN ACCURACY: 0.850\n",
      "TEST ACCURACY: 0.840\n",
      "Epoch: 111/200 cost: 0.661439040\n",
      "TRAIN ACCURACY: 0.870\n",
      "TEST ACCURACY: 0.844\n",
      "Epoch: 115/200 cost: 0.643284917\n",
      "TRAIN ACCURACY: 0.810\n",
      "TEST ACCURACY: 0.847\n"
     ]
    }
   ],
   "source": [
    "training_epochs = 200\n",
    "batch_size      = 100\n",
    "display_step    = 4\n",
    "# LAUNCH THE GRAPH\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "# OPTIMIZE\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0.\n",
    "    total_batch = int(mnist.train.num_examples/batch_size)\n",
    "    # ITERATION\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        feeds = {x: batch_xs, y: batch_ys}\n",
    "        sess.run(optm, feed_dict=feeds)\n",
    "        avg_cost += sess.run(cost, feed_dict=feeds)\n",
    "    avg_cost = avg_cost / total_batch\n",
    "    # DISPLAY\n",
    "    if (epoch+1) % display_step == 0:\n",
    "        print (\"Epoch: %03d/%03d cost: %.9f\" % (epoch, training_epochs, avg_cost))\n",
    "        feeds = {x: batch_xs, y: batch_ys}\n",
    "        train_acc = sess.run(accr, feed_dict=feeds)\n",
    "        print (\"TRAIN ACCURACY: %.3f\" % (train_acc))\n",
    "        feeds = {x: mnist.test.images, y: mnist.test.labels}\n",
    "        test_acc = sess.run(accr, feed_dict=feeds)\n",
    "        print (\"TEST ACCURACY: %.3f\" % (test_acc))\n",
    "print (\"OPTIMIZATION FINISHED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
